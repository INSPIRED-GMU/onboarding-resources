See also: [Scrapy homepage](https://scrapy.org), [Official documentation](http://doc.scrapy.org), [Scrapy snippets on Snipplr](http://snipplr.com/users/scrapy/tags/scrapy/)

## Getting started

If you're new to Scrapy, start by reading [Scrapy at a glance](http://doc.scrapy.org/en/latest/intro/overview.html).

## Course (Online)

Check https://scrapy.org/resources/.

## Google Summer of Code

* [GSoC 2016](http://gsoc2016.scrapinghub.com/)
* [GSoC 2015](http://gsoc2015.scrapinghub.com/)
* [[GSoC 2014]]

## Scrappy help docs and resources

Check https://scrapy.org/resources/ 

- Articles & blog posts
- Books
- Videos
- Slides

## Projects, tools and libraries using Scrapy

* [Django Dynamic Scraper](https://github.com/holgerd77/django-dynamic-scraper) - a web application (written in django) for runnning and controlling Scrapy spiders
* [Slybot](https://github.com/scrapy/slybot) - A supervised learning crawler based on [Scrapely](https://github.com/scrapy/scrapely)
* [scrapy-sentry](https://pypi.python.org/pypi/scrapy-sentry) - Logs Scrapy exceptions into Sentry
* [ScrapyGraphite](https://pypi.python.org/pypi/ScrapyGraphite) - Output scrapy statistics to carbon/graphite
* [scrapy-mongo](https://pypi.python.org/pypi/scrapy-mongodb) - A pipeline to store scrapy items in a MongoDB database
* [scrapy-boilerplate](https://pypi.python.org/pypi/scrapy-boilerplate) - small set of utilities to simplify writing low-complexity spiders
* [scrapy-inline-requests](https://pypi.python.org/pypi/scrapy-inline-requests) - provides a decorator to write spider callbacks which performs multiple requests without the need to write multiple callbacks for each request
* [scrapy-redis](https://pypi.python.org/pypi/scrapy-redis) - providesRedis-backed components for Scrapy
* [scrapyz](https://github.com/ssteuteville/scrapyz) - Create simple spiders easily.
* [Scrapy-related libraries on PyPI](https://pypi.python.org/pypi?%3Aaction=search&term=scrapy&submit=search)
* [Scrapy_cn](https://github.com/addwork/scrapy_cn) - provided a demo to solve encoding problems(utf-8).
* [elite-proxies-scrapy-middleware](https://github.com/garrylachman/elite-proxies-scrapy-middleware) - get new proxies from your EliteProxies account
* [scrapydo](https://github.com/rolando/scrapydo) - Crochet-based blocking API for Scrapy.

## Companies using Scrapy

See http://scrapy.org/companies/

## Release Notes

* see [Release notes](http://doc.scrapy.org/en/latest/news.html) in the official documentation

## Developer documentation

* [[Scrapy Release Procedure]]
* [[Asyncio use cases]]

## Scrapy Enhancement Proposals

* SEPs are available in [scrapy/sep](https://github.com/scrapy/scrapy/tree/master/sep).